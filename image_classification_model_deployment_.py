# -*- coding: utf-8 -*-
"""Image_Classification_Model_Deployment..ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SCnRu74V7IdZQBzqINtX7lzuLjTSzpf2

# Informasi Diri
## Nama: Muhammad Lahia Ardhan
## Username: lahiardhan
## Email: lahia.ardhanm@gmail.com

# Import Library
"""

import zipfile
import os
import shutil
import tensorflow as tf
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import img_to_array, load_img
from tensorflow.keras.preprocessing import image
from os import getcwd
import pathlib
import numpy as np
import tensorflow_datasets as tfds
from tensorflow.keras import regularizers

"""# Download the Dataset"""

filePath = f"{getcwd()}/../tmp2/"

(train_examples, validation_examples), info = tfds.load('fashion_mnist',
                                                        data_dir=filePath,
                                                        with_info=True,
                                                        as_supervised=True,
                                                        split=['train[:80%]',
                                                                'train[80%:]'])

num_examples = info.splits['train'].num_examples
num_classes = info.features['label'].num_classes

print(f'Total data: {len(train_examples) + len(validation_examples)}')
print(f'Jumlah data training: {len(train_examples)}')
print(f'Jumlah data validation: {len(validation_examples)}')

class_names = ['T-shirt_top', 'Trouser', 'Pullover', 'Dress', 'Coat',
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

# Create a labels.txt file with the class names
with open('labels.txt', 'w') as f:
    f.write('\n'.join(class_names))

# The images in the dataset are 28 by 28 pixels.
IMG_SIZE = 28

"""# Preprocessing Data

## Preprocess
"""

def format_example(image, label):
    image = tf.cast(image, dtype=tf.float32)
    image = image/255.0 # Normalize the image in the range [0, 1]

    return image, label

# Specify the batch size
BATCH_SIZE = 256

"""## Create Datasets From Images and Labels"""

# Create Datasets
train_batches = train_examples.cache().shuffle(num_examples//4).batch(BATCH_SIZE).map(format_example).prefetch(1)
validation_batches = validation_examples.cache().batch(BATCH_SIZE).map(format_example)

"""# Build the model"""

model = tf.keras.Sequential([
    tf.keras.layers.Conv2D(filters=16, kernel_size=3, input_shape=(28, 28, 1), activation='relu'),
    tf.keras.layers.MaxPooling2D(),
    tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(units=64, activation='relu'),
    tf.keras.layers.Dense(units=10, activation='softmax')])

model.compile(optimizer='RMSprop',
              loss="sparse_categorical_crossentropy",
              metrics=["accuracy"])

model.summary()

"""# Train the model"""

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('val_accuracy') > 0.9 and epoch >= 10):
      print("\nAkurasi melewati 90%, hentikan proses training!")
      self.model.stop_training = True

callbacks = myCallback()

from tensorflow.keras.callbacks import EarlyStopping

history = model.fit(
    train_batches,
    epochs = 20,
    validation_data = validation_batches,
    verbose =2,
    callbacks=[callbacks]
)

"""# Model Evaluation"""

# Dapatkan nilai akurasi dan loss dari objek History
train_accuracy = history.history['accuracy']
val_accuracy = history.history['val_accuracy']
train_loss = history.history['loss']
val_loss = history.history['val_loss']

# Plot grafik akurasi
plt.plot(range(1, len(train_accuracy) + 1), train_accuracy, label='Training Accuracy')
plt.plot(range(1, len(val_accuracy) + 1), val_accuracy, label='Validation Accuracy')
plt.title('Akurasi Training dan Validation')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()
print("")

# Plot grafik loss
plt.plot(range(1, len(train_loss) + 1), train_loss, label='Training Loss')
plt.plot(range(1, len(val_loss) + 1), val_loss, label='Validation Loss')
plt.title('Loss Training dan Validation')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

"""# Exporting to TFLite

"""

export_dir = 'saved_model/1'
tf.saved_model.save(model, export_dir)

# Select mode of optimization
mode = "Speed"

if mode == 'Storage':
    optimization = tf.lite.Optimize.OPTIMIZE_FOR_SIZE
elif mode == 'Speed':
    optimization = tf.lite.Optimize.OPTIMIZE_FOR_LATENCY
else:
    optimization = tf.lite.Optimize.DEFAULT

converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)
converter.optimizations = [optimization] # Set the optimzations

# Invoke the converter to finally generate the TFLite model
tflite_model = converter.convert()

tflite_model_file = pathlib.Path('./model.tflite')
tflite_model_file.write_bytes(tflite_model)